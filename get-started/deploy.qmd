---
title: "Deploy"
format:
  html:
    toc: true
---

```{r}
#| include: false
#| message: false

library(tidyverse)
library(tidymodels)
library(vetiver)
library(pins)
hotels <- read_csv('https://tidymodels.org/start/case-study/hotels.csv')

set.seed(123)
hotel_split <- initial_split(hotels, strata = children)
hotel_train <- training(hotel_split)
hotel_test  <- testing(hotel_split)

rf_recipe <- 
  recipe(children ~ ., data = hotel_train) %>% 
  step_date(arrival_date) %>% 
  step_holiday(arrival_date, keep_original_cols = FALSE)
rf_spec <- rand_forest(mode = "classification")

set.seed(234)
rf_fit <-
    workflow(rf_recipe, rf_spec) %>%
    fit(sample_frac(hotel_train, 0.5))

v <- vetiver_model(rf_fit, "hotel_rf")
model_board <- board_temp()
model_board %>% vetiver_pin_write(v)
```


## Deploy your model

You can deploy your model by creating a special [Plumber](https://www.rplumber.io/) router in R or a [FastAPI](https://fastapi.tiangolo.com/) router in Python, and adding a POST endpoint for making predictions.

::: panel-tabset

## R 

```{r}
library(plumber)
pr() %>%
  vetiver_api(v)
```

To start a server using this object, pipe (`%>%`) to `pr_run(port = 8088)` or your port of choice.

## Python

```{python}
1 + 1
```

:::

You can interact with your vetiver API locally and debug it. FastAPI and Plumber APIs such as these can be hosted in a variety of ways. You can create a ready-to-go file for deployment that is especially suited for [RStudio Connect](https://www.rstudio.com/products/connect/).

::: panel-tabset

## R 

```{r}
vetiver_write_plumber(model_board, "hotel_rf")
```

```{r}
#| echo: false
#| comment: ""
tmp <- tempfile()
vetiver_write_plumber(model_board, "hotel_rf", file = tmp)
cat(readr::read_lines(tmp), sep = "\n")
```

For RStudio Connect, you can streamline this deployment process even more by using `vetiver_deploy_rsconnect(model_board, "hotel_rf)`.

## Python

```{python}
1 + 1
```

:::

In a real-world situation, you would see something like `b <- board_rsconnect()` or `b <- board_s3()` here instead of our temporary demo board. 

::: callout-tip
Notice that the deployment is strongly linked to a specific version of the pinned model; if you pin another version of the model after you deploy your model, your deployed model will not be affected.
:::

## Generate a Dockerfile

## Predict from your model endpoint
